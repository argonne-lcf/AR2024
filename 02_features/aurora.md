---
layout: page

theme: dark
permalink: features/aurora

title: Aurora Nears Full Deployment
hero-mp4-source: "aurora_pan.mp4"
hero-img-source: ALCF_AuroraSkin.jpg
hero-img-caption: "The Aurora team uses a specialized machine to install the supercomputer’s blades."
intro: "The system surpassed the exascale barrier, demonstrated its world-class AI capabilities, and completed critical preparations for its release to the research community in 2025."

aside: alcf-4.md
---

In 2024, the ALCF made significant progress toward the full deployment of its Aurora exascale supercomputer for scientific research. After completing extensive system validation, verification, and scale-up efforts, Aurora is undergoing acceptance testing in December 2024, with plans to enter full production mode in January 2025.

Once operational, it will provide the research community with powerful simulation, AI, and data analysis capabilities to drive breakthroughs in physics, engineering, materials science, and other domains.

## Breaking the Exascale Barrier

Over the course of the year, Aurora demonstrated its capabilities in various performance benchmarks that solidified its place among the world’s most powerful supercomputers. The ALCF system officially broke the exascale barrier in June, achieving 1.012 exaflops on the High Performance LINPACK (HPL) benchmark. Aurora also set a new record for AI performance, registering 11.6 exaflops on the HPL-MxP mixed-precision benchmark. Its strengths in data-intensive applications were further highlighted with leading results on the Graph500 and HPCG benchmarks, while its storage system, DAOS, retained the top ranking on the IO500 production list.

Together with Oak Ridge National Laboratory’s Frontier and Lawrence Livermore National Laboratory’s El Capitan, DOE is now home to the world’s first three exascale systems. These machines not only mark the first to reach exascale but are also the three fastest supercomputers on the TOP500 List.

Built in partnership with Intel and HPE, Aurora’s architecture represents a first-of-its-kind deployment, integrating cutting-edge technologies at an unprecedented scale. Equipped with 63,744 GPUs and 84,992 network endpoints, the system is designed to tackle complex computational challenges in ways that were previously unimaginable.


{% include media-video.html
   embed-code= '<iframe src="https://www.youtube.com/embed/djEzdORj0F0?si=2FBUZcgIVLey9ywP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>'
   caption= "Quick brown fox"
   credit= "Argonne National Laboratory"
%}

## World-Class Simulation, AI, and Data Capabilities

Aurora’s computing power and advanced capabilities are expected to transform research across a wide range of scientific domains. Ahead of the system’s deployment, teams participating in DOE’s Exascale Computing Project (ECP) the ALCF’s Aurora Early Science Program (ESP) have demonstrated its potential in training large-scale AI models and carrying out extreme-scale modeling and simulation campaigns.

One key target involves the development of AI-driven scientific models that can accelerate discovery across multiple disciplines, including materials design, drug development, and energy research. The system is also being prepared to support high-fidelity simulations of complex systems, such as the human circulatory system, nuclear reactors, and supernovae, to gain new insights into their behavior. Additionally, its capacity to process massive datasets will be critical for analyzing the growing data streams from large-scale research facilities such as Argonne’s Advanced Photon Source and CERN’s Large Hadron Collider.

## Preparing for Science on Day One

Bringing a system of this scale online has required close collaboration among the ALCF, Intel, HPE, and researchers from the DOE’s Exascale Computing Project and Aurora Early Science Program. Throughout 2024, these teams worked to optimize codes and stress-test the system, ensuring it would be ready for science from day one of production.

A co-design approach was essential in this effort, with hardware and software developed in tandem to maximize performance and usability. As part of this process, researchers ran early science applications to fine-tune their software for Aurora’s architecture, resulting in a suite of computational tools that will be ready to accelerate discoveries as soon as the system becomes fully operational.

With acceptance testing underway and final preparations in progress, Aurora is poised to take its place at the forefront of scientific computing in January 2025. As it moves into production, it will provide researchers with a transformative platform for tackling some of the most ambitious challenges in science and engineering.
