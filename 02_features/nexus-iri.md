---
layout: page

theme: dark
permalink: features/nexus-iri

title: Linking Experimental Facilities and Leadership Computing
hero-img-source: polaris+aps_1600x900.jpg
hero-img-caption: "The co-location of the ALCF and APS at Argonne provides an ideal environment for developing and demonstrating capabilities for a broader Integrated Research Infrastructure."
intro: "Argonne researchers are working to advance the DOE’s vision by integrating experimental facilities with ALCF computing resources."
---


As the volume of data generated by large-scale experiments continues to grow, the need for rapid data analysis capabilities is becoming increasingly critical to new discoveries. 

Argonne’s Advanced Photon Source Upgrade project (APS-U), for example, completed in 2024, increased the brightness of APS x-rays by as much as 500 times. With a corresponding increase in the amounts of experimental data generated, to quickly process and analyze the results requires the use of high-performance computing (HPC) systems.

Numerous ALCF activities and achievements have helped realize the DOE effort to build an Integrated Research Structure (IRI) that seamlessly connects experimental facilities with its world-class supercomputing resources, including:

-	Developing and testing methods to closely integrate supercomputers and experiments for near-real-time data analysis.
-	Partnering with Pathfinder projects to advance plasma physics and fusion energy research.
-	Participating in leadership groups and technical subcommittees dedicated to the design and implementation of computing facility functionality useful for experimentalists.


# Nexus
Under [Argonne's Nexus effort](https://www.anl.gov/nexus-connect), Argonne researchers are working to advance the DOE’s vision by integrating experimental facilities with ALCF computing resources. 

As IRI aims to deliver DOE-enterprise-wide infrastructure for computing, ALCF has continued its commitment to linking experimental facilities with ALCF computing. Work with APS over recent years has been a primary driver for defining new functionality and services ALCF has deployed to satisfy experiment-time computing needs at APS beamlines. Service accounts enable APS users to leverage automated analysis of their data at ALCF in a shared environment in a streamlined fashion throughout their multi-day beamline campaigns, with jobs running immediately at experiment time in the on-demand queue on Polaris. Analysis results are available to scientists at the beamline via Globus Sharing enabled on the Eagle filesystem, at the time of experiment and post-hoc. Building on these ALCF-deployed features, Globus Compute and Globus Flows manage application execution and data transfer in a frictionless manner, for projects across the DOE-SC program offices.


# Facility Integration

For over a decade, the ALCF and the APS have been collaborating to build the infrastructure for integrated ALCF-APS research, including the development of workflow management tools and enable secure access to on-demand computing.

With the upgraded APS providing x-rays up to 500 times brighter than before with, the APS-ALCF collaboration is providing increased computational power at experiment time. More than 20 beamlines housed at the APS identified significant computing needs and have engaged the full power of ALCF's Nexus services and functionality, using service accounts for transparent access to ALCF, and the demand queue for time-sensitive analysis of beamline data through integration with the APS Data Management system. With more beamlines coming online with ever greater computational needs, the APS demand for ALCF supercomputing resources and newly upgraded inter-facility network connectivity will continue to grow.

Working with a team at the Lawrence Berkeley National Laboratory Advanced Light Source, ALCF staff have helped to automate analysis of data from a tomography beamline on Polaris. Using a service account to submit jobs to Polaris through Globus Compute and the demand queue to analyze data at experiment time, the team has moved beyond an initial prototype and is now able to run analysis in a dedicated discretionary allocation. This production-ready capability is planned to be used in upcoming beamline experiments.

# Expanding and Demonstrating Capabilities

In a recent achievement of facility integration for near-real-time data analysis, Argonne deployed a fully automated pipeline that uses ALCF resources to rapidly process data obtained from the x-ray experiments at the APS.

To demonstrate the capabilities of the pipeline, [Argonne researchers carried out a study](https://www.alcf.anl.gov/news/argonne-team-demonstrates-rapid-cross-facility-data-processing) focused on a technique called Laue microdiffraction, which is employed at the APS and other light sources to analyze materials with crystalline structures. The team used the ALCF’s Polaris supercomputer to reconstruct data obtained from an APS experiment, returning reconstructed scans to the APS within 15 minutes of them being sent to the ALCF. The beamline technique introduced in the study allows users to collect data about 10 times faster than was previously possible.
These results carry implications for future software development, engineering, and beamline science.
Argonne researchers showcased the use of the Polaris system for processing data from APS experiments in near-real time during a demonstration at the SC24 conference.

Additional experiments and papers presented at the SC24 XLOOP workshop explored multiple IRI-related issues, including the scaling capabilities of file-based reconstruction of ptychography data—which requires particularly short data-processing turnaround times. New scans on the APS beamline storage system were automatically transferred to ALCF’s Eagle file system through Globus using the file-based workflow, which automatically launched reconstruction jobs on Polaris compute nodes using an on-demand queue. Once the reconstruction results were available on Eagle, they were transferred back to the APS through the same Globus transfer workflow.

# Partnering to Advance Energy Technologies
DIII-D runs experiments on a 20-minute cycle that requires time-sensitive analysis of experimental data from one experiment to inform and prepare for the next experiment. Working closely with the DIII-D team, and combining efforts with a team at NERSC, ALCF staff detailed the needs for an ion orbital simulation application (IonOrb and a kinetic equilibrium application CAKE. In weekly meetings throughout the year, we established service accounts for the DIII-D team, worked with them to leverage a discretionary IRI allocation, installed their software and required local proprietary databases, and enabled outbound connectivity to communicate with systems at the DIII-D facility to exchange input and output data. This work culminated in production-ready analysis during experiments at DIII-D using Globus Flows to analyze data automatically between experiments, running CAKE on Perlmutter at NERSC and IonOrb on Polaris at ALCF. The IonOrb application used up to 40 nodes in the demand queue on Polaris during a week-long experiment run; attendees of the SC24 conference were given a glimpse into this running experiment in the DOE conference booth.



# Leading the Future of Inter-Facility Science

ALCF staff participate in and co-chair weekly Leadership Group meetings to direct overall IRI efforts and specific tasks for technical subcommittees, form new subcommittees, and work with the Pathfinder projects. In 2024, ALCF staff served on the organizing committee for the [IRI/HPDF](https://www.hpdf.science/) kickoff meeting in Gaithersburg, Maryland, and produced related materials describing outcomes from the meeting. ALCF staff also presented during the Leadership Group's participation in the DOE ASCAC meeting in May 2024.

ALCF staff have participated in all existing IRI technical subcommittees from day one, including Outreach and Engagement, Interfaces, and TRUSTID. These groups are dedicated to designing and building functionality at computing facilities to facilitate their use by experimentalists.
